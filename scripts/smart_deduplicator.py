#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£–º–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –∫–∞–Ω–∞–ª–æ–≤
–í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–π –ø–æ—Ç–æ–∫ –∏–∑ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –∫–∞–Ω–∞–ª–æ–≤
"""

import os
import re
import json
import hashlib
import time
import subprocess
from pathlib import Path
from collections import defaultdict
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SmartDeduplicator:
    def __init__(self, base_dir="/Users/ipont/projects/iptv"):
        self.base_dir = Path(base_dir)
        self.categories_dir = self.base_dir / "categories"
        self.reports_dir = self.base_dir / "reports"
        self.reports_dir.mkdir(exist_ok=True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        self.quality_checks = {
            "timeout": 10,
            "max_redirects": 3,
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ—Ç–æ–∫–∞
        self.quality_criteria = {
            "url_quality": {
                "https": 10,
                "http": 5,
                "m3u8": 8,
                "ts": 6,
                "flv": 3,
                "rtmp": 2
            },
            "domain_quality": {
                "cdn": 10,
                "stream": 8,
                "live": 7,
                "iptv": 6,
                "ott": 5,
                "localhost": 1,
                "127.0.0.1": 1
            },
            "resolution_quality": {
                "4k": 10,
                "uhd": 10,
                "fhd": 8,
                "hd": 6,
                "720p": 6,
                "480p": 4,
                "360p": 2
            }
        }

    def normalize_channel_name(self, name):
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        normalized = re.sub(r'[^\w\s]', '', name.lower())
        normalized = re.sub(r'\s+', ' ', normalized).strip()
        
        # –£–±–∏—Ä–∞–µ–º –æ–±—â–∏–µ —Å—É—Ñ—Ñ–∏–∫—Å—ã
        suffixes = ['hd', 'fhd', '4k', 'uhd', 'sd', '+2', '+3', '+0', 'orig', 'original']
        for suffix in suffixes:
            if normalized.endswith(' ' + suffix):
                normalized = normalized[:-len(' ' + suffix)]
        
        return normalized

    def calculate_url_quality_score(self, url):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ URL –ø–æ—Ç–æ–∫–∞"""
        score = 0
        url_lower = url.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª
        for protocol, points in self.quality_criteria["url_quality"].items():
            if protocol in url_lower:
                score += points
                break
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ–º–µ–Ω
        for domain, points in self.quality_criteria["domain_quality"].items():
            if domain in url_lower:
                score += points
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
        for resolution, points in self.quality_criteria["resolution_quality"].items():
            if resolution in url_lower:
                score += points
        
        # –ë–æ–Ω—É—Å –∑–∞ –¥–ª–∏–Ω—É URL (–±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ –æ–±—ã—á–Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ)
        score += min(len(url) / 100, 5)
        
        return score

    def check_stream_availability(self, url):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –ø–æ—Ç–æ–∫–∞"""
        try:
            # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ curl
            cmd = [
                'curl', '-s', '-I', '--max-time', str(self.quality_checks["timeout"]),
                '--max-redirs', str(self.quality_checks["max_redirects"]),
                '-A', self.quality_checks["user_agent"],
                url
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=15)
            
            if result.returncode == 0:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
                headers = result.stdout.lower()
                if any(code in headers for code in ['200', '302', '301']):
                    return True
                if 'content-type' in headers and 'video' in headers:
                    return True
            
            return False
            
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ {url}: {e}")
            return False

    def deduplicate_channels(self):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏"""
        logger.info("üîÑ –ù–ê–ß–ò–ù–ê–ï–ú –£–ú–ù–£–Æ –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–Æ")
        logger.info("=" * 50)
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–∞–Ω–∞–ª—ã –∏–∑ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        all_channels = []
        
        for category_file in self.categories_dir.glob("*.m3u"):
            if category_file.name == "18+.m3u":
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º 18+ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                
            category_name = category_file.stem
            logger.info(f"üìÇ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é: {category_name}")
            
            channels = self.read_channels_from_file(category_file)
            for channel in channels:
                channel['category'] = category_name
                channel['normalized_name'] = self.normalize_channel_name(channel['name'])
                channel['url_quality_score'] = self.calculate_url_quality_score(channel['url'])
                all_channels.append(channel)
        
        logger.info(f"üìä –í—Å–µ–≥–æ –∫–∞–Ω–∞–ª–æ–≤ —Å–æ–±—Ä–∞–Ω–æ: {len(all_channels)}")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏—è–º
        duplicates = defaultdict(list)
        unique_channels = []
        
        for channel in all_channels:
            normalized = channel['normalized_name']
            if len(normalized) > 3:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
                duplicates[normalized].append(channel)
            else:
                unique_channels.append(channel)
        
        logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(duplicates)}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –≥—Ä—É–ø–ø—É –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        processed_count = 0
        removed_groups = 0
        for normalized_name, channels in duplicates.items():
            if len(channels) > 1:
                logger.info(f"  üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã: '{normalized_name}' ({len(channels)} –∫–∞–Ω–∞–ª–æ–≤)")
                
                # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –∫–∞–Ω–∞–ª
                best_channel = self.select_best_channel(channels)
                if best_channel:
                    unique_channels.append(best_channel)
                    processed_count += len(channels) - 1
                    logger.info(f"    ‚úÖ –í—ã–±—Ä–∞–Ω: {best_channel['name']} (–∫–∞—á–µ—Å—Ç–≤–æ: {best_channel['url_quality_score']:.1f})")
                else:
                    processed_count += len(channels)
                    removed_groups += 1
                    logger.info(f"    ‚ùå –£–¥–∞–ª–µ–Ω–∞ –≥—Ä—É–ø–ø–∞: {normalized_name} (–≤—Å–µ –ø–æ—Ç–æ–∫–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç)")
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–∞–Ω–∞–ª
                if self.check_stream_availability(channels[0]['url']):
                    unique_channels.append(channels[0])
                else:
                    processed_count += 1
                    logger.info(f"    ‚ùå –£–¥–∞–ª–µ–Ω –Ω–µ—Ä–∞–±–æ—á–∏–π –∫–∞–Ω–∞–ª: {channels[0]['name']}")
        
        logger.info(f"üìä –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {processed_count}")
        logger.info(f"üìä –ò—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤: {len(unique_channels)}")
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        self.create_deduplicated_categories(unique_channels)
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
        self.create_deduplication_report(duplicates, processed_count)
        
        logger.info("‚úÖ –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")

    def select_best_channel(self, channels):
        """–í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–π –∫–∞–Ω–∞–ª –∏–∑ –≥—Ä—É–ø–ø—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É URL
        channels.sort(key=lambda x: x['url_quality_score'], reverse=True)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ç–æ–ø-3 –∫–∞–Ω–∞–ª–æ–≤
        for i, channel in enumerate(channels[:3]):
            logger.debug(f"    üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å: {channel['name']}")
            if self.check_stream_availability(channel['url']):
                logger.debug(f"    ‚úÖ –ü–æ—Ç–æ–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç: {channel['name']}")
                return channel
            else:
                logger.debug(f"    ‚ùå –ü–æ—Ç–æ–∫ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {channel['name']}")
        
        # –ï—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - –ù–ï –í–û–ó–í–†–ê–©–ê–ï–ú –ù–ò–ß–ï–ì–û
        logger.warning(f"    ‚ùå –í–°–ï –ü–û–¢–û–ö–ò –ù–ï –†–ê–ë–û–¢–ê–Æ–¢ - –£–î–ê–õ–Ø–ï–ú –ì–†–£–ü–ü–£")
        return None

    def read_channels_from_file(self, file_path):
        """–ß–∏—Ç–∞–µ—Ç –∫–∞–Ω–∞–ª—ã –∏–∑ M3U —Ñ–∞–π–ª–∞"""
        channels = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            i = 0
            while i < len(lines):
                line = lines[i].strip()
                if line.startswith('#EXTINF:'):
                    if i + 1 < len(lines):
                        url = lines[i + 1].strip()
                        if url and not url.startswith('#'):
                            name_match = re.search(r',(.+)$', line)
                            if name_match:
                                name = name_match.group(1).strip()
                                channels.append({
                                    'name': name,
                                    'url': url,
                                    'extinf': line
                                })
                i += 1
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")
        
        return channels

    def create_deduplicated_categories(self, unique_channels):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        logger.info("üìù –°–û–ó–î–ê–ï–ú –û–ß–ò–©–ï–ù–ù–´–ï –ö–ê–¢–ï–ì–û–†–ò–ò")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        categories = defaultdict(list)
        for channel in unique_channels:
            categories[channel['category']].append(channel)
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã
        for category, channels in categories.items():
            file_path = self.categories_dir / f"{category}.m3u"
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write("#EXTM3U\n")
                f.write(f"# {self.get_category_emoji(category)} {category.title()}\n")
                f.write(f"# –ö–∞–Ω–∞–ª–æ–≤: {len(channels)}\n")
                f.write(f"# –û–±–Ω–æ–≤–ª–µ–Ω–æ: {self.get_current_time()}\n")
                f.write(f"# –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: –∞–∫—Ç–∏–≤–Ω–∞\n")
                f.write("\n")
                
                for channel in channels:
                    f.write(f"{channel['extinf']}\n")
                    f.write(f"{channel['url']}\n")
                    f.write("\n")
            
            logger.info(f"  üìÇ {category}: {len(channels)} –∫–∞–Ω–∞–ª–æ–≤")

    def get_category_emoji(self, category):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–º–æ–¥–∑–∏ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        emojis = {
            "—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ": "üì∫",
            "—Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ": "üèòÔ∏è",
            "–Ω–æ–≤–æ—Å—Ç–∏": "üì∞",
            "—Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–µ": "‚öΩ",
            "–º—É–∑—ã–∫–∞–ª—å–Ω—ã–µ": "üéµ",
            "–¥–µ—Ç—Å–∫–∏–µ": "üë∂",
            "–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å–Ω—ã–µ": "üß†",
            "—Ä–∞–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–µ": "üéâ",
            "–∫–∏–Ω–æ_–∏_—Å–µ—Ä–∏–∞–ª—ã": "üé¨",
            "—Ä–µ–ª–∏–≥–∏–æ–∑–Ω—ã–µ": "‚õ™",
            "–∏–Ω—Ñ–æ": "‚ÑπÔ∏è",
            "—Ä–∞–¥–∏–æ": "üìª",
            "18+": "üîû",
            "fashion": "üëó",
            "relax": "üßò",
            "–∫–∏–Ω–æ–∑–∞–ª—ã": "üé≠"
        }
        return emojis.get(category, "üì∫")

    def create_deduplication_report(self, duplicates, removed_count):
        """–°–æ–∑–¥–∞–µ—Ç –æ—Ç—á–µ—Ç –æ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏"""
        report = {
            "timestamp": self.get_current_time(),
            "total_duplicates_removed": removed_count,
            "duplicate_groups": len(duplicates),
            "groups_details": {}
        }
        
        for normalized_name, channels in duplicates.items():
            if len(channels) > 1:
                report["groups_details"][normalized_name] = {
                    "count": len(channels),
                    "channels": [
                        {
                            "name": ch['name'],
                            "url": ch['url'],
                            "quality_score": ch['url_quality_score'],
                            "category": ch['category']
                        } for ch in channels
                    ]
                }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_file = self.reports_dir / f"deduplication_report_{int(time.time())}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üìä –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")

    def get_current_time(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
        from datetime import datetime
        return datetime.now().strftime("%d.%m.%Y %H:%M")

def main():
    deduplicator = SmartDeduplicator()
    deduplicator.deduplicate_channels()

if __name__ == "__main__":
    main()
