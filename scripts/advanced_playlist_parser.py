#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø–∞—Ä—Å–µ—Ä –ø–ª–µ–π–ª–∏—Å—Ç–æ–≤ —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
"""

import requests
import re
import json
import os
import asyncio
import aiohttp
from datetime import datetime
from urllib.parse import urlparse
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AdvancedPlaylistParser:
    def __init__(self, config_file='donors_config.json'):
        self.config = self.load_config(config_file)
        self.stats = {
            'total_parsed': 0,
            'added_channels': 0,
            'skipped_channels': 0,
            'invalid_channels': 0,
            'categories_updated': set(),
            'donors_processed': 0,
            'donors_failed': 0
        }
    
    def load_config(self, config_file):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            logger.info(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {config_file}")
            return config
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            return {
                "donors": {},
                "category_mapping": {},
                "settings": {"auto_update": True}
            }
    
    def download_playlist(self, url, timeout=30):
        """–°–∫–∞—á–∏–≤–∞–µ—Ç –ø–ª–µ–π–ª–∏—Å—Ç —Å URL"""
        try:
            logger.info(f"–°–∫–∞—á–∏–≤–∞–µ–º –ø–ª–µ–π–ª–∏—Å—Ç: {url}")
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
            response = requests.get(url, headers=headers, timeout=timeout)
            response.raise_for_status()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É
            content = response.content
            encodings = ['utf-8', 'cp1251', 'latin1', 'iso-8859-1']
            
            for encoding in encodings:
                try:
                    playlist_content = content.decode(encoding)
                    logger.info(f"–ü–ª–µ–π–ª–∏—Å—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π {encoding}, —Ä–∞–∑–º–µ—Ä: {len(playlist_content)} —Å–∏–º–≤–æ–ª–æ–≤")
                    return playlist_content
                except UnicodeDecodeError:
                    continue
            
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º errors='ignore'
            playlist_content = content.decode('utf-8', errors='ignore')
            logger.warning("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∫–∞ —Å –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º –æ—à–∏–±–æ–∫")
            return playlist_content
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –ø–ª–µ–π–ª–∏—Å—Ç–∞ {url}: {e}")
            return None
    
    def parse_m3u_playlist(self, content):
        """–ü–∞—Ä—Å–∏—Ç M3U –ø–ª–µ–π–ª–∏—Å—Ç –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞–Ω–∞–ª—ã"""
        channels = []
        lines = content.splitlines()
        current_extinf = None
        
        for line_num, line in enumerate(lines, 1):
            line = line.strip()
            
            if line.startswith('#EXTINF'):
                current_extinf = line
            elif line and not line.startswith('#') and current_extinf:
                try:
                    # –ü–∞—Ä—Å–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–Ω–∞–ª–µ
                    channel_info = self.parse_extinf(current_extinf)
                    channel_info['url'] = line
                    channel_info['line_number'] = line_num
                    
                    # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è URL
                    if self.is_valid_url(line):
                        channels.append(channel_info)
                    else:
                        logger.debug(f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π URL –Ω–∞ —Å—Ç—Ä–æ–∫–µ {line_num}: {line}")
                        self.stats['invalid_channels'] += 1
                        
                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –∫–∞–Ω–∞–ª–∞ –Ω–∞ —Å—Ç—Ä–æ–∫–µ {line_num}: {e}")
                    self.stats['invalid_channels'] += 1
                
                current_extinf = None
        
        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ –∫–∞–Ω–∞–ª–æ–≤: {len(channels)}, –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö: {self.stats['invalid_channels']}")
        return channels
    
    def is_valid_url(self, url):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å URL"""
        try:
            parsed = urlparse(url)
            return bool(parsed.scheme and parsed.netloc)
        except:
            return False
    
    def parse_extinf(self, extinf_line):
        """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É #EXTINF –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ"""
        info = {
            'name': '',
            'group': '',
            'logo': '',
            'tvg_id': '',
            'catchup': '',
            'original_extinf': extinf_line
        }
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞ (–ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –∑–∞–ø—è—Ç–æ–π)
        name_match = re.search(r',([^,]+)$', extinf_line)
        if name_match:
            info['name'] = name_match.group(1).strip()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
        attributes = {
            'group': r'group-title="([^"]*)"',
            'logo': r'tvg-logo="([^"]*)"',
            'tvg_id': r'tvg-id="([^"]*)"',
            'catchup': r'catchup="([^"]*)"'
        }
        
        for attr, pattern in attributes.items():
            match = re.search(pattern, extinf_line)
            if match:
                info[attr] = match.group(1).strip()
        
        return info
    
    def categorize_channel(self, channel):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∫–∞–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        name = channel['name'].lower()
        group = channel['group'].lower()
        text_to_check = f"{name} {group}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        for category, rules in self.config.get('category_mapping', {}).items():
            keywords = rules.get('keywords', [])
            exclude = rules.get('exclude', [])
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            keyword_found = False
            for keyword in keywords:
                if keyword.lower() in text_to_check:
                    keyword_found = True
                    break
            
            if keyword_found:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏—è
                excluded = False
                for exclude_word in exclude:
                    if exclude_word.lower() in text_to_check:
                        excluded = True
                        break
                
                if not excluded:
                    return category
        
        return None
    
    def load_existing_channels(self, category_file):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–∞–Ω–∞–ª—ã –∏–∑ —Ñ–∞–π–ª–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        if not os.path.exists(category_file):
            return set()
        
        existing_urls = set()
        try:
            with open(category_file, 'r', encoding='utf-8') as f:
                content = f.read()
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ URL –∏–∑ —Ñ–∞–π–ª–∞
                for line in content.splitlines():
                    line = line.strip()
                    if line and not line.startswith('#'):
                        existing_urls.add(line)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {category_file}: {e}")
        
        return existing_urls
    
    def add_channel_to_category(self, channel, category):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∫–∞–Ω–∞–ª –≤ —Ñ–∞–π–ª –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        category_file = f"categories/{category}.m3u"
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É categories –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs("categories", exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–∞–Ω–∞–ª—ã
        existing_urls = self.load_existing_channels(category_file)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        if self.config.get('settings', {}).get('check_duplicates', True):
            if channel['url'] in existing_urls:
                logger.debug(f"–ö–∞–Ω–∞–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {channel['name']}")
                self.stats['skipped_channels'] += 1
                return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –∫–∞–Ω–∞–ª–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        max_channels = self.config.get('settings', {}).get('max_channels_per_category', 1000)
        if len(existing_urls) >= max_channels:
            logger.warning(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∫–∞–Ω–∞–ª–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}: {max_channels}")
            self.stats['skipped_channels'] += 1
            return False
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–∞–ª
        try:
            # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            if not os.path.exists(category_file):
                with open(category_file, 'w', encoding='utf-8') as f:
                    f.write("#EXTM3U\n")
                    f.write(f"# –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}\n")
                    f.write("# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–æ\n\n")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–∞–ª –≤ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞
            with open(category_file, 'a', encoding='utf-8') as f:
                f.write(f"{channel['original_extinf']}\n")
                f.write(f"{channel['url']}\n\n")
            
            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω –∫–∞–Ω–∞–ª '{channel['name']}' –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—é '{category}'")
            self.stats['added_channels'] += 1
            self.stats['categories_updated'].add(category)
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –∫–∞–Ω–∞–ª–∞ –≤ {category_file}: {e}")
            return False
    
    def update_category_headers(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ñ–∞–π–ª–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∫–∞–Ω–∞–ª–æ–≤"""
        for category in self.stats['categories_updated']:
            category_file = f"categories/{category}.m3u"
            if os.path.exists(category_file):
                try:
                    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
                    with open(category_file, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                    
                    # –°—á–∏—Ç–∞–µ–º –∫–∞–Ω–∞–ª—ã
                    channel_count = sum(1 for line in lines if line.strip() and not line.startswith('#'))
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    with open(category_file, 'w', encoding='utf-8') as f:
                        f.write("#EXTM3U\n")
                        f.write(f"# –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}\n")
                        f.write(f"# –ö–∞–Ω–∞–ª–æ–≤: {channel_count}\n")
                        f.write(f"# –û–±–Ω–æ–≤–ª–µ–Ω–æ: {datetime.now().strftime('%d.%m.%Y %H:%M')}\n\n")
                        
                        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∫–∞–Ω–∞–ª—ã (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏)
                        skip_headers = True
                        for line in lines:
                            if line.startswith('#EXTINF'):
                                skip_headers = False
                            if not skip_headers:
                                f.write(line)
                
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞ {category_file}: {e}")
    
    async def validate_channel_url(self, session, url, timeout=5):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å URL –∫–∞–Ω–∞–ª–∞"""
        try:
            async with session.head(url, timeout=timeout) as response:
                return response.status in [200, 206, 301, 302, 307, 308]
        except:
            return False
    
    async def validate_channels(self, channels, max_concurrent=10):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤"""
        if not self.config.get('settings', {}).get('validate_urls', False):
            return channels
        
        logger.info(f"–í–∞–ª–∏–¥–∏—Ä—É–µ–º {len(channels)} –∫–∞–Ω–∞–ª–æ–≤...")
        
        connector = aiohttp.TCPConnector(limit=max_concurrent)
        timeout = aiohttp.ClientTimeout(total=10)
        
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            tasks = []
            for channel in channels:
                task = self.validate_channel_url(session, channel['url'])
                tasks.append((channel, task))
            
            valid_channels = []
            for channel, task in tasks:
                try:
                    is_valid = await task
                    if is_valid:
                        valid_channels.append(channel)
                    else:
                        self.stats['invalid_channels'] += 1
                except:
                    self.stats['invalid_channels'] += 1
        
        logger.info(f"–í–∞–ª–∏–¥–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤: {len(valid_channels)}")
        return valid_channels
    
    def process_donor_playlist(self, donor_name, donor_config):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –¥–æ–Ω–æ—Ä—Å–∫–∏–π –ø–ª–µ–π–ª–∏—Å—Ç"""
        if not donor_config.get('enabled', True):
            logger.info(f"–î–æ–Ω–æ—Ä {donor_name} –æ—Ç–∫–ª—é—á–µ–Ω")
            return False
        
        logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–Ω–æ—Ä–∞: {donor_name}")
        
        # –°–∫–∞—á–∏–≤–∞–µ–º –ø–ª–µ–π–ª–∏—Å—Ç
        content = self.download_playlist(donor_config['url'])
        if not content:
            self.stats['donors_failed'] += 1
            return False
        
        # –ü–∞—Ä—Å–∏–º –∫–∞–Ω–∞–ª—ã
        channels = self.parse_m3u_playlist(content)
        self.stats['total_parsed'] += len(channels)
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∫–∞–Ω–∞–ª—ã –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
        if self.config.get('settings', {}).get('validate_urls', False):
            channels = asyncio.run(self.validate_channels(channels))
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –∫–∞–Ω–∞–ª
        for channel in channels:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            category = self.categorize_channel(channel)
            
            if category:
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                self.add_channel_to_category(channel, category)
            else:
                logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å: {channel['name']} ({channel['group']})")
                self.stats['skipped_channels'] += 1
        
        self.stats['donors_processed'] += 1
        return True
    
    def process_all_donors(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ—Ö –¥–æ–Ω–æ—Ä–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        logger.info("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤—Å–µ—Ö –¥–æ–Ω–æ—Ä–æ–≤...")
        
        donors = self.config.get('donors', {})
        if not donors:
            logger.warning("–ù–µ—Ç –¥–æ–Ω–æ—Ä–æ–≤ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            return
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–æ–Ω–æ—Ä–æ–≤ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        sorted_donors = sorted(donors.items(), key=lambda x: x[1].get('priority', 999))
        
        for donor_name, donor_config in sorted_donors:
            try:
                self.process_donor_playlist(donor_name, donor_config)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–Ω–æ—Ä–∞ {donor_name}: {e}")
                self.stats['donors_failed'] += 1
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        self.update_category_headers()
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.print_statistics()
    
    def print_statistics(self):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        logger.info("=" * 60)
        logger.info("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò –ü–õ–ï–ô–õ–ò–°–¢–û–í:")
        logger.info(f"–î–æ–Ω–æ—Ä–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.stats['donors_processed']}")
        logger.info(f"–î–æ–Ω–æ—Ä–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏: {self.stats['donors_failed']}")
        logger.info(f"–í—Å–µ–≥–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–æ –∫–∞–Ω–∞–ª–æ–≤: {self.stats['total_parsed']}")
        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤: {self.stats['added_channels']}")
        logger.info(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ –∫–∞–Ω–∞–ª–æ–≤: {self.stats['skipped_channels']}")
        logger.info(f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤: {self.stats['invalid_channels']}")
        logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {len(self.stats['categories_updated'])}")
        
        if self.stats['categories_updated']:
            logger.info("–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:")
            for category in sorted(self.stats['categories_updated']):
                category_file = f"categories/{category}.m3u"
                if os.path.exists(category_file):
                    with open(category_file, 'r', encoding='utf-8') as f:
                        channel_count = sum(1 for line in f if line.strip() and not line.startswith('#'))
                    logger.info(f"  - {category}: {channel_count} –∫–∞–Ω–∞–ª–æ–≤")
        
        logger.info("=" * 60)
    
    def add_donor(self, name, url, enabled=True, priority=999):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤–æ–≥–æ –¥–æ–Ω–æ—Ä–∞ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
        if 'donors' not in self.config:
            self.config['donors'] = {}
        
        self.config['donors'][name] = {
            'url': url,
            'enabled': enabled,
            'priority': priority,
            'description': f'–î–æ–±–∞–≤–ª–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ {datetime.now().strftime("%d.%m.%Y")}'
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        try:
            with open('donors_config.json', 'w', encoding='utf-8') as f:
                json.dump(self.config, f, ensure_ascii=False, indent=2)
            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –¥–æ–Ω–æ—Ä: {name} -> {url}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø–∞—Ä—Å–µ—Ä IPTV –ø–ª–µ–π–ª–∏—Å—Ç–æ–≤')
    parser.add_argument('--config', default='donors_config.json', help='–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
    parser.add_argument('--validate', action='store_true', help='–í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å URL –∫–∞–Ω–∞–ª–æ–≤')
    parser.add_argument('--add-donor', nargs=2, metavar=('NAME', 'URL'), help='–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤–æ–≥–æ –¥–æ–Ω–æ—Ä–∞')
    
    args = parser.parse_args()
    
    parser_instance = AdvancedPlaylistParser(args.config)
    
    if args.validate:
        parser_instance.config['settings']['validate_urls'] = True
    
    if args.add_donor:
        name, url = args.add_donor
        parser_instance.add_donor(name, url)
        return
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ—Ö –¥–æ–Ω–æ—Ä–æ–≤
    parser_instance.process_all_donors()
    
    print("\nüéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("üìÅ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞–ø–∫—É 'categories/' –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –ø–ª–µ–π–ª–∏—Å—Ç–æ–≤")

if __name__ == "__main__":
    main()
