#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
‚ö° –ë–´–°–¢–†–ê–Ø –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–Ø –ü–û –ò–°–¢–û–ß–ù–ò–ö–ê–ú
–û—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ 3 –ª—É—á—à–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞ + 18+ + –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å 4000+ –∫–∞–Ω–∞–ª–æ–≤
"""

import os
import re
import json
import time
from pathlib import Path
from collections import defaultdict
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FastDeduplicator:
    def __init__(self, base_dir="/Users/ipont/projects/iptv"):
        self.base_dir = Path(base_dir)
        self.categories_dir = self.base_dir / "categories"
        self.reports_dir = self.base_dir / "reports"
        self.reports_dir.mkdir(exist_ok=True)
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —ç—Ç–∏)
        self.priority_sources = [
            "iptvshared",  # IPTVSHARED (TAPTV_PREMIUM)
            "18+"          # 18+ –∫–æ–Ω—Ç–µ–Ω—Ç
        ]
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ URL
        self.url_quality = {
            "https": 10,
            "http": 5,
            "m3u8": 8,
            "ts": 6,
            "rtmp": 2
        }
    
    def analyze_sources(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∫–∞–Ω–∞–ª–æ–≤"""
        logger.info("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏...")
        
        source_stats = defaultdict(lambda: {
            'count': 0,
            'categories': set(),
            'channels': []
        })
        
        for category_file in self.categories_dir.glob("*.m3u"):
            category_name = category_file.stem
            logger.info(f"üìÇ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º: {category_name}")
            
            channels = self.read_channels_from_file(category_file)
            
            for channel in channels:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –ø–æ URL
                source = self.detect_source(channel['url'])
                
                source_stats[source]['count'] += 1
                source_stats[source]['categories'].add(category_name)
                source_stats[source]['channels'].append({
                    'name': channel['name'],
                    'url': channel['url'],
                    'category': category_name
                })
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        logger.info("\n" + "="*60)
        logger.info("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò–°–¢–û–ß–ù–ò–ö–û–í")
        logger.info("="*60)
        
        sorted_sources = sorted(source_stats.items(), key=lambda x: x[1]['count'], reverse=True)
        
        for source, stats in sorted_sources:
            logger.info(f"{source:20} | {stats['count']:5} –∫–∞–Ω–∞–ª–æ–≤ | {len(stats['categories']):2} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
        
        logger.info("="*60)
        
        return source_stats
    
    def detect_source(self, url):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ –ø–æ URL"""
        url_lower = url.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º IPTVSHARED –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        if 'iptvshared' in url_lower or 'taptv' in url_lower or '5.129.242.227' in url_lower:
            return 'iptvshared'
        elif '18+' in url_lower or 'adult' in url_lower or 'porn' in url_lower:
            return '18+'
        elif 'githubusercontent.com' in url_lower and 'iptv' in url_lower:
            return 'iptvshared'  # GitHub IPTV —Å–ø–∏—Å–∫–∏
        else:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ –¥–æ–º–µ–Ω—É
            domain = url.split('/')[2] if '://' in url else 'unknown'
            return domain.split('.')[-2] if '.' in domain else 'unknown'
    
    def read_channels_from_file(self, file_path):
        """–ß–∏—Ç–∞–µ—Ç –∫–∞–Ω–∞–ª—ã –∏–∑ M3U —Ñ–∞–π–ª–∞"""
        channels = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            current_name = None
            
            for line in lines:
                line = line.strip()
                if line.startswith('#EXTINF'):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                    parts = line.split(',', 1)
                    if len(parts) > 1:
                        current_name = parts[1].strip()
                elif line and not line.startswith('#'):
                    if current_name:
                        channels.append({
                            'name': current_name,
                            'url': line
                        })
                    current_name = None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path}: {e}")
        
        return channels
    
    def calculate_url_quality(self, url):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ URL"""
        score = 0
        url_lower = url.lower()
        
        for pattern, points in self.url_quality.items():
            if pattern in url_lower:
                score += points
                break
        
        return score
    
    def select_best_channels(self, source_stats):
        """–í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–µ –∫–∞–Ω–∞–ª—ã –∏–∑ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        logger.info("üéØ –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–µ –∫–∞–Ω–∞–ª—ã...")
        
        selected_channels = []
        total_selected = 0
        
        # 1. –û—Å—Ç–∞–≤–ª—è–µ–º IPTVSHARED (–æ—Å–Ω–æ–≤–Ω–æ–π)
        if 'iptvshared' in source_stats:
            iptvshared_channels = source_stats['iptvshared']['channels']
            selected_channels.extend(iptvshared_channels)
            total_selected += len(iptvshared_channels)
            logger.info(f"‚úÖ IPTVSHARED: {len(iptvshared_channels)} –∫–∞–Ω–∞–ª–æ–≤")
        
        # 2. –û—Å—Ç–∞–≤–ª—è–µ–º 18+ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if '18+' in source_stats:
            adult_channels = source_stats['18+']['channels']
            selected_channels.extend(adult_channels)
            total_selected += len(adult_channels)
            logger.info(f"‚úÖ 18+: {len(adult_channels)} –∫–∞–Ω–∞–ª–æ–≤")
        
        # 3. –ï—Å–ª–∏ IPTVSHARED –º–∞–ª–æ –∫–∞–Ω–∞–ª–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫
        if 'iptvshared' in source_stats and source_stats['iptvshared']['count'] < 100:
            sorted_sources = sorted(
                [(s, stats) for s, stats in source_stats.items() 
                 if s not in ['iptvshared', '18+']], 
                key=lambda x: x[1]['count'], 
                reverse=True
            )
            
            if sorted_sources:
                big_source, big_stats = sorted_sources[0]
                big_channels = big_stats['channels']
                selected_channels.extend(big_channels)
                total_selected += len(big_channels)
                logger.info(f"‚úÖ {big_source}: {len(big_channels)} –∫–∞–Ω–∞–ª–æ–≤ (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π)")
        
        logger.info(f"üìä –ò—Ç–æ–≥–æ –≤—ã–±—Ä–∞–Ω–æ: {total_selected} –∫–∞–Ω–∞–ª–æ–≤")
        return selected_channels
    
    def deduplicate_by_name(self, channels):
        """–ë—ã—Å—Ç—Ä–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º (–±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ—Ç–æ–∫–æ–≤)"""
        logger.info("üîÑ –ë—ã—Å—Ç—Ä–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º...")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏—è–º
        name_groups = defaultdict(list)
        
        for channel in channels:
            normalized = self.normalize_name(channel['name'])
            if len(normalized) > 3:
                name_groups[normalized].append(channel)
        
        # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –∏–∑ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã
        unique_channels = []
        duplicates_removed = 0
        
        for normalized_name, group in name_groups.items():
            if len(group) > 1:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É URL
                group.sort(key=lambda x: self.calculate_url_quality(x['url']), reverse=True)
                unique_channels.append(group[0])  # –ë–µ—Ä–µ–º –ª—É—á—à–∏–π
                duplicates_removed += len(group) - 1
            else:
                unique_channels.append(group[0])
        
        logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_removed}")
        logger.info(f"üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤: {len(unique_channels)}")
        
        return unique_channels
    
    def normalize_name(self, name):
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞"""
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
        normalized = re.sub(r'[^\w\s]', '', name.lower())
        normalized = re.sub(r'\s+', ' ', normalized).strip()
        
        # –£–±–∏—Ä–∞–µ–º —Å—É—Ñ—Ñ–∏–∫—Å—ã –∫–∞—á–µ—Å—Ç–≤–∞
        suffixes = ['hd', 'fhd', '4k', 'uhd', 'sd', '+2', '+3', 'orig']
        for suffix in suffixes:
            if normalized.endswith(' ' + suffix):
                normalized = normalized[:-len(' ' + suffix)]
        
        return normalized
    
    def create_new_categories(self, channels):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤"""
        logger.info("üìÅ –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏...")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        category_groups = defaultdict(list)
        
        for channel in channels:
            category = channel.get('category', '–æ–±—â–∏–µ')
            category_groups[category].append(channel)
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        for category, cat_channels in category_groups.items():
            if not cat_channels:
                continue
                
            file_path = self.categories_dir / f"{category}.m3u"
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write('#EXTM3U\n')
                for channel in cat_channels:
                    f.write(f"#EXTINF:-1,{channel['name']}\n")
                    f.write(f"{channel['url']}\n")
            
            logger.info(f"‚úÖ {category}: {len(cat_channels)} –∫–∞–Ω–∞–ª–æ–≤")
    
    def create_report(self, source_stats, selected_channels):
        """–°–æ–∑–¥–∞–µ—Ç –æ—Ç—á–µ—Ç –æ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º sets –≤ lists –¥–ª—è JSON
        serializable_stats = {}
        for source, stats in source_stats.items():
            serializable_stats[source] = {
                'count': stats['count'],
                'categories': list(stats['categories']),
                'channels_count': len(stats['channels'])
            }
        
        report = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'method': 'fast_deduplication',
            'sources_analyzed': len(source_stats),
            'channels_selected': len(selected_channels),
            'sources_kept': ['iptvshared', '18+'],
            'source_stats': serializable_stats
        }
        
        report_path = self.reports_dir / f"fast_dedup_report_{int(time.time())}.json"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üìä –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
    
    def run(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –±—ã—Å—Ç—Ä—É—é –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é"""
        logger.info("‚ö° –ë–´–°–¢–†–ê–Ø –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–Ø")
        logger.info("=" * 50)
        
        start_time = time.time()
        
        # 1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        source_stats = self.analyze_sources()
        
        # 2. –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–µ –∫–∞–Ω–∞–ª—ã
        selected_channels = self.select_best_channels(source_stats)
        
        # 3. –î–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ–º –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º
        unique_channels = self.deduplicate_by_name(selected_channels)
        
        # 4. –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        self.create_new_categories(unique_channels)
        
        # 5. –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
        self.create_report(source_stats, unique_channels)
        
        elapsed = time.time() - start_time
        
        logger.info("\n" + "="*60)
        logger.info("‚úÖ –ë–´–°–¢–†–ê–Ø –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
        logger.info("="*60)
        logger.info(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed:.1f} —Å–µ–∫—É–Ω–¥")
        logger.info(f"üìä –ö–∞–Ω–∞–ª–æ–≤ –≤—ã–±—Ä–∞–Ω–æ: {len(unique_channels)}")
        logger.info(f"üöÄ –°–∫–æ—Ä–æ—Å—Ç—å: {len(unique_channels)/elapsed:.1f} –∫–∞–Ω–∞–ª–æ–≤/—Å–µ–∫")
        logger.info("="*60)

def main():
    deduplicator = FastDeduplicator()
    deduplicator.run()

if __name__ == "__main__":
    main()
