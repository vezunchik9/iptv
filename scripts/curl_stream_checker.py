#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ IPTV –ø–æ—Ç–æ–∫–æ–≤ —á–µ—Ä–µ–∑ curl
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∞–ª—å–Ω—É—é —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø–æ—Ç–æ–∫–æ–≤
"""

import asyncio
import subprocess
import json
import time
import re
import threading
import queue
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from urllib.parse import urlparse
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class CurlStreamChecker:
    def __init__(self, timeout=30, max_concurrent=10, test_duration=15):
        self.timeout = timeout
        self.max_concurrent = max_concurrent
        self.test_duration = test_duration
        self.results = {}
        self.checking = False
        
    def _check_stream_with_curl_detailed(self, url, test_duration=15):
        """–î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ç–æ–∫–∞ —á–µ—Ä–µ–∑ curl —Å –∞–Ω–∞–ª–∏–∑–æ–º —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            # –ö–æ–º–∞–Ω–¥–∞ curl –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ç–æ–∫–∞
            cmd = [
                'curl',
                '-s',                    # –¢–∏—Ö–∏–π —Ä–µ–∂–∏–º
                '--max-time', str(test_duration),
                '--connect-timeout', '10',
                '--retry', '0',         # –ù–µ –ø–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å—ã
                '--retry-delay', '0',
                '--user-agent', 'VLC/3.0.0 LibVLC/3.0.0',
                '--location',            # –°–ª–µ–¥—É–µ–º —Ä–µ–¥–∏—Ä–µ–∫—Ç–∞–º
                '--fail-with-body',
                '--write-out', 'HTTP_CODE:%{http_code}|TIME_TOTAL:%{time_total}|SPEED_DOWNLOAD:%{speed_download}|SIZE_DOWNLOAD:%{size_download}|CONNECT_TIME:%{time_connect}|STARTTRANSFER_TIME:%{time_starttransfer}|REDIRECT_TIME:%{time_redirect}|REDIRECT_COUNT:%{num_redirects}',
                '--output', '/dev/null',
                url
            ]
            
            start_time = time.time()
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )
            
            duration = time.time() - start_time
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç curl
            if result.returncode == 0 and result.stdout:
                try:
                    # –ü–∞—Ä—Å–∏–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                    info = {}
                    for part in result.stdout.strip().split('|'):
                        if ':' in part:
                            key, value = part.split(':', 1)
                            try:
                                # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ
                                info[key] = float(value) if '.' in value else int(value)
                            except ValueError:
                                info[key] = value
                    
                    http_code = info.get('HTTP_CODE', 0)
                    time_total = info.get('TIME_TOTAL', 0)
                    speed_download = info.get('SPEED_DOWNLOAD', 0)
                    size_download = info.get('SIZE_DOWNLOAD', 0)
                    connect_time = info.get('CONNECT_TIME', 0)
                    starttransfer_time = info.get('STARTTRANSFER_TIME', 0)
                    redirect_count = info.get('REDIRECT_COUNT', 0)
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–∞
                    working = False
                    quality_score = 0
                    issues = []
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ HTTP –∫–æ–¥–∞
                    if http_code == 200:
                        quality_score += 30
                    elif http_code in [301, 302, 307, 308]:
                        quality_score += 20
                        issues.append(f"Redirect (code {http_code})")
                    else:
                        issues.append(f"HTTP error {http_code}")
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∑–∫–∏
                    if speed_download > 100000:  # > 100KB/s
                        quality_score += 40
                    elif speed_download > 10000:  # > 10KB/s
                        quality_score += 20
                    elif speed_download > 1000:   # > 1KB/s
                        quality_score += 10
                    else:
                        issues.append(f"Low speed: {speed_download:.0f} bytes/s")
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                    if size_download > 1000000:  # > 1MB
                        quality_score += 20
                    elif size_download > 100000:  # > 100KB
                        quality_score += 10
                    elif size_download < 1000:    # < 1KB
                        issues.append(f"Small download: {size_download} bytes")
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                    if connect_time < 2:
                        quality_score += 10
                    elif connect_time > 10:
                        issues.append(f"Slow connection: {connect_time:.1f}s")
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ –±–∞–π—Ç–∞
                    if starttransfer_time < 5:
                        quality_score += 10
                    elif starttransfer_time > 15:
                        issues.append(f"Slow start: {starttransfer_time:.1f}s")
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å
                    working = quality_score >= 60 and http_code in [200, 301, 302, 307, 308]
                    
                    return {
                        'method': 'curl_detailed',
                        'success': True,
                        'working': working,
                        'quality_score': quality_score,
                        'duration': duration,
                        'http_code': http_code,
                        'speed_download': speed_download,
                        'size_download': size_download,
                        'connect_time': connect_time,
                        'starttransfer_time': starttransfer_time,
                        'redirect_count': redirect_count,
                        'issues': issues,
                        'error': None if working else '; '.join(issues)
                    }
                    
                except (ValueError, KeyError) as e:
                    return {
                        'method': 'curl_detailed',
                        'success': False,
                        'working': False,
                        'duration': duration,
                        'error': f'Parse error: {str(e)}'
                    }
            
            return {
                'method': 'curl_detailed',
                'success': False,
                'working': False,
                'duration': duration,
                'error': result.stderr.strip() if result.stderr else f'curl failed with code {result.returncode}'
            }
            
        except subprocess.TimeoutExpired:
            return {
                'method': 'curl_detailed',
                'success': False,
                'working': False,
                'duration': self.timeout,
                'error': 'curl timeout'
            }
        except Exception as e:
            return {
                'method': 'curl_detailed',
                'success': False,
                'working': False,
                'duration': 0,
                'error': str(e)
            }
    
    def _check_stream_with_curl_chunks(self, url, test_duration=15):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ç–æ–∫–∞ —á–µ—Ä–µ–∑ curl —Å –∞–Ω–∞–ª–∏–∑–æ–º –ø–æ —á–∞–Ω–∫–∞–º (–¥–ª—è HLS)"""
        try:
            # –î–ª—è HLS –ø–æ—Ç–æ–∫–æ–≤ –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å playlist –∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            parsed_url = urlparse(url)
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–ª–µ–π–ª–∏—Å—Ç–∞
            playlist_cmd = [
                'curl',
                '-s',
                '--max-time', '10',
                '--connect-timeout', '5',
                '--user-agent', 'VLC/3.0.0 LibVLC/3.0.0',
                '--location',
                '--write-out', 'HTTP_CODE:%{http_code}|SIZE_DOWNLOAD:%{size_download}',
                '--output', '/dev/null',
                url
            ]
            
            result = subprocess.run(playlist_cmd, capture_output=True, text=True, timeout=15)
            
            if result.returncode != 0:
                return {
                    'method': 'curl_chunks',
                    'success': False,
                    'working': False,
                    'duration': 0,
                    'error': 'Playlist not accessible'
                }
            
            # –ü–∞—Ä—Å–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–ª–µ–π–ª–∏—Å—Ç–µ
            playlist_info = {}
            for part in result.stdout.strip().split('|'):
                if ':' in part:
                    key, value = part.split(':', 1)
                    try:
                        playlist_info[key] = float(value) if '.' in value else int(value)
                    except ValueError:
                        playlist_info[key] = value
            
            # –ï—Å–ª–∏ —ç—Ç–æ HLS –ø–ª–µ–π–ª–∏—Å—Ç, –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            if url.endswith('.m3u8') or 'm3u8' in url:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–ª–µ–π–ª–∏—Å—Ç–∞
                try:
                    playlist_content_cmd = [
                        'curl',
                        '-s',
                        '--max-time', '10',
                        '--user-agent', 'VLC/3.0.0 LibVLC/3.0.0',
                        url
                    ]
                    
                    content_result = subprocess.run(
                        playlist_content_cmd, 
                        capture_output=True, 
                        text=True, 
                        timeout=10
                    )
                    
                    if content_result.returncode == 0 and content_result.stdout:
                        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–ª–µ–π–ª–∏—Å—Ç
                        lines = content_result.stdout.splitlines()
                        segment_urls = []
                        
                        for line in lines:
                            line = line.strip()
                            if line and not line.startswith('#'):
                                # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π URL
                                if line.startswith('/'):
                                    segment_url = f"{parsed_url.scheme}://{parsed_url.netloc}{line}"
                                elif line.startswith('http'):
                                    segment_url = line
                                else:
                                    # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
                                    base_url = '/'.join(url.split('/')[:-1])
                                    segment_url = f"{base_url}/{line}"
                                
                                segment_urls.append(segment_url)
                        
                        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                        working_segments = 0
                        total_segments = min(3, len(segment_urls))
                        
                        for i, segment_url in enumerate(segment_urls[:total_segments]):
                            segment_cmd = [
                                'curl',
                                '-s',
                                '--max-time', '5',
                                '--connect-timeout', '3',
                                '--user-agent', 'VLC/3.0.0 LibVLC/3.0.0',
                                '--write-out', 'HTTP_CODE:%{http_code}|SIZE_DOWNLOAD:%{size_download}',
                                '--output', '/dev/null',
                                segment_url
                            ]
                            
                            seg_result = subprocess.run(segment_cmd, capture_output=True, text=True, timeout=8)
                            
                            if seg_result.returncode == 0:
                                seg_info = {}
                                for part in seg_result.stdout.strip().split('|'):
                                    if ':' in part:
                                        key, value = part.split(':', 1)
                                        try:
                                            seg_info[key] = float(value) if '.' in value else int(value)
                                        except ValueError:
                                            seg_info[key] = value
                                
                                if seg_info.get('HTTP_CODE') == 200 and seg_info.get('SIZE_DOWNLOAD', 0) > 1000:
                                    working_segments += 1
                        
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                        working = working_segments > 0
                        quality_score = (working_segments / total_segments) * 100 if total_segments > 0 else 0
                        
                        return {
                            'method': 'curl_chunks',
                            'success': True,
                            'working': working,
                            'quality_score': quality_score,
                            'duration': time.time() - time.time(),
                            'playlist_accessible': playlist_info.get('HTTP_CODE') == 200,
                            'segments_found': len(segment_urls),
                            'segments_tested': total_segments,
                            'segments_working': working_segments,
                            'error': None if working else f'Only {working_segments}/{total_segments} segments working'
                        }
                
                except Exception as e:
                    logger.debug(f"Error analyzing HLS playlist: {e}")
            
            # –î–ª—è –æ–±—ã—á–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–ª–µ–π–ª–∏—Å—Ç–∞
            working = playlist_info.get('HTTP_CODE') == 200 and playlist_info.get('SIZE_DOWNLOAD', 0) > 0
            
            return {
                'method': 'curl_chunks',
                'success': True,
                'working': working,
                'quality_score': 80 if working else 0,
                'duration': 0,
                'playlist_accessible': playlist_info.get('HTTP_CODE') == 200,
                'segments_found': 0,
                'segments_tested': 0,
                'segments_working': 0,
                'error': None if working else 'Playlist not accessible'
            }
            
        except Exception as e:
            return {
                'method': 'curl_chunks',
                'success': False,
                'working': False,
                'duration': 0,
                'error': str(e)
            }
    
    def check_single_stream_curl(self, channel_id, url, test_duration=None):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–¥–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ —á–µ—Ä–µ–∑ curl —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
        if test_duration is None:
            test_duration = self.test_duration
            
        start_time = time.time()
        
        result = {
            'channel_id': channel_id,
            'url': url,
            'checked_at': datetime.now().isoformat(),
            'response_time': None,
            'working': False,
            'quality_score': 0,
            'details': None,
            'error': None,
            'test_duration': test_duration
        }
        
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
            detailed_result = self._check_stream_with_curl_detailed(url, test_duration)
            
            # –ï—Å–ª–∏ —ç—Ç–æ HLS –ø–æ—Ç–æ–∫, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
            if url.endswith('.m3u8') or 'm3u8' in url:
                chunks_result = self._check_stream_with_curl_chunks(url, test_duration)
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                if chunks_result.get('working', False):
                    result['working'] = True
                    result['quality_score'] = max(
                        detailed_result.get('quality_score', 0),
                        chunks_result.get('quality_score', 0)
                    )
                    result['details'] = {
                        'detailed': detailed_result,
                        'chunks': chunks_result
                    }
                else:
                    result['working'] = detailed_result.get('working', False)
                    result['quality_score'] = detailed_result.get('quality_score', 0)
                    result['details'] = detailed_result
                    result['error'] = detailed_result.get('error')
            else:
                # –î–ª—è –æ–±—ã—á–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –¥–µ—Ç–∞–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
                result['working'] = detailed_result.get('working', False)
                result['quality_score'] = detailed_result.get('quality_score', 0)
                result['details'] = detailed_result
                result['error'] = detailed_result.get('error')
            
            result['response_time'] = round((time.time() - start_time) * 1000, 2)
            
        except Exception as e:
            result['error'] = str(e)
            result['response_time'] = round((time.time() - start_time) * 1000, 2)
        
        return result
    
    async def check_multiple_streams_curl(self, channels, test_duration=None, progress_callback=None):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ—Ç–æ–∫–æ–≤ —á–µ—Ä–µ–∑ curl –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ"""
        self.checking = True
        self.results = {}
        
        try:
            total = len(channels)
            completed = 0
            
            # –°–æ–∑–¥–∞–µ–º –ø—É–ª –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–≤–µ—Ä–æ–∫
            with ThreadPoolExecutor(max_workers=self.max_concurrent) as executor:
                
                # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏
                loop = asyncio.get_event_loop()
                tasks = []
                
                for channel in channels:
                    task = loop.run_in_executor(
                        executor,
                        self.check_single_stream_curl,
                        channel['id'],
                        channel['url'],
                        test_duration
                    )
                    tasks.append((channel, task))
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ä–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
                for channel, task in tasks:
                    try:
                        result = await task
                        
                        self.results[channel['id']] = result
                        completed += 1
                        
                        if progress_callback:
                            progress_callback(completed, total, result)
                        
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–∞–Ω–∞–ª–∞ {channel['id']}: {e}")
                        completed += 1
            
            return self.results
            
        finally:
            self.checking = False
    
    def get_statistics(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        if not self.results:
            return {}
        
        total = len(self.results)
        working = sum(1 for r in self.results.values() if r['working'])
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        quality_scores = [r['quality_score'] for r in self.results.values() if r['quality_score'] > 0]
        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –ø–æ—Ç–æ–∫–æ–≤
        hls_count = sum(1 for r in self.results.values() 
                       if r['url'].endswith('.m3u8') or 'm3u8' in r['url'])
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–æ–±–ª–µ–º–∞–º
        speed_issues = sum(1 for r in self.results.values() 
                          if r.get('details', {}).get('issues') and 
                          any('speed' in issue.lower() for issue in r['details']['issues']))
        
        connection_issues = sum(1 for r in self.results.values() 
                               if r.get('details', {}).get('issues') and 
                               any('connection' in issue.lower() or 'connect' in issue.lower() 
                                   for issue in r['details']['issues']))
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
        response_times = [r['response_time'] for r in self.results.values() 
                         if r['response_time'] is not None]
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        
        return {
            'total_checked': total,
            'working': working,
            'success_rate': round((working / total) * 100, 2) if total > 0 else 0,
            'avg_response_time': round(avg_response_time, 2),
            'avg_quality_score': round(avg_quality, 2),
            'hls_streams': hls_count,
            'speed_issues': speed_issues,
            'connection_issues': connection_issues,
            'checked_at': datetime.now().isoformat()
        }
    
    def load_channels_from_m3u(self, m3u_file):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞–Ω–∞–ª—ã –∏–∑ M3U —Ñ–∞–π–ª–∞"""
        channels = []
        
        try:
            with open(m3u_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.splitlines()
            current_extinf = None
            channel_id = 0
            
            for line in lines:
                line = line.strip()
                
                if line.startswith('#EXTINF'):
                    current_extinf = line
                elif line and not line.startswith('#') and current_extinf:
                    # –ü–∞—Ä—Å–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–Ω–∞–ª–µ
                    name_match = re.search(r',(.*)$', current_extinf)
                    name = name_match.group(1).strip() if name_match else f"Channel {channel_id}"
                    
                    group_match = re.search(r'group-title="([^"]*)"', current_extinf)
                    group = group_match.group(1) if group_match else "Unknown"
                    
                    channels.append({
                        'id': channel_id,
                        'name': name,
                        'url': line,
                        'group': group
                    })
                    
                    channel_id += 1
                    current_extinf = None
            
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(channels)} –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è curl –ø—Ä–æ–≤–µ—Ä–∫–∏")
            return channels
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ M3U: {e}")
            return []
    
    def save_results(self, filename):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON —Ñ–∞–π–ª"""
        try:
            report = {
                'statistics': self.get_statistics(),
                'results': self.results,
                'generated_at': datetime.now().isoformat(),
                'checker_version': '3.1_curl_advanced',
                'settings': {
                    'timeout': self.timeout,
                    'max_concurrent': self.max_concurrent,
                    'test_duration': self.test_duration
                }
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            logger.info(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
            return False

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    import argparse
    
    parser = argparse.ArgumentParser(description='–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ IPTV –ø–æ—Ç–æ–∫–æ–≤ —á–µ—Ä–µ–∑ curl')
    parser.add_argument('m3u_file', help='–ü—É—Ç—å –∫ M3U —Ñ–∞–π–ª—É')
    parser.add_argument('--output', '-o', help='–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞')
    parser.add_argument('--timeout', type=int, default=30, help='–¢–∞–π–º–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö')
    parser.add_argument('--concurrent', type=int, default=10, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫')
    parser.add_argument('--test-duration', type=int, default=15, help='–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞ –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ç–æ–∫–∞')
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç–µ–ª—å
    checker = CurlStreamChecker(
        timeout=args.timeout,
        max_concurrent=args.concurrent,
        test_duration=args.test_duration
    )
    
    print("üì° –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–Ω–∞–ª–æ–≤...")
    channels = checker.load_channels_from_m3u(args.m3u_file)
    
    if not channels:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞–Ω–∞–ª—ã")
        return
    
    print(f"üåê –ù–∞—á–∏–Ω–∞–µ–º –£–õ–£–ß–®–ï–ù–ù–£–Æ –ø—Ä–æ–≤–µ—Ä–∫—É {len(channels)} –∫–∞–Ω–∞–ª–æ–≤ —á–µ—Ä–µ–∑ curl...")
    print(f"‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏: —Ç–∞–π–º–∞—É—Ç={args.timeout}—Å, –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ={args.concurrent}, —Ç–µ—Å—Ç={args.test_duration}—Å")
    
    def progress_callback(completed, total, result):
        status = "‚úÖ" if result['working'] else "‚ùå"
        quality = result.get('quality_score', 0)
        speed = 0
        if result.get('details'):
            if isinstance(result['details'], dict) and 'detailed' in result['details']:
                speed = result['details']['detailed'].get('speed_download', 0)
            elif isinstance(result['details'], dict):
                speed = result['details'].get('speed_download', 0)
        
        speed_kb = speed / 1024 if speed > 0 else 0
        print(f"[{completed}/{total}] {result['channel_id']}: {result['url'][:50]}... "
              f"{status} (–∫–∞—á–µ—Å—Ç–≤–æ: {quality}%, —Å–∫–æ—Ä–æ—Å—Ç—å: {speed_kb:.1f}KB/s)")
    
    start_time = time.time()
    results = await checker.check_multiple_streams_curl(channels, args.test_duration, progress_callback)
    duration = time.time() - start_time
    
    print(f"\nüéØ –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {duration:.1f} —Å–µ–∫—É–Ω–¥")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = checker.get_statistics()
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"  –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {stats['total_checked']}")
    print(f"  –†–∞–±–æ—Ç–∞—é—â–∏—Ö: {stats['working']} ({stats['success_rate']}%)")
    print(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {stats['avg_response_time']}–º—Å")
    print(f"  –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –∫–∞—á–µ—Å—Ç–≤–∞: {stats['avg_quality_score']}")
    print(f"  HLS –ø–æ—Ç–æ–∫–æ–≤: {stats['hls_streams']}")
    print(f"  –ü—Ä–æ–±–ª–µ–º—ã —Å–æ —Å–∫–æ—Ä–æ—Å—Ç—å—é: {stats['speed_issues']}")
    print(f"  –ü—Ä–æ–±–ª–µ–º—ã —Å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ–º: {stats['connection_issues']}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    if args.output:
        checker.save_results(args.output)
    else:
        default_filename = f"curl_stream_check_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        checker.save_results(default_filename)

if __name__ == "__main__":
    asyncio.run(main())
